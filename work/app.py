import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from io import BytesIO
from reportlab.lib.pagesizes import LETTER
from reportlab.pdfgen import canvas
from reportlab.lib.units import inch
from textwrap import wrap


from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
pdfmetrics.registerFont(UnicodeCIDFont("HYSMyeongJo-Medium"))



from privacy_news_monitor.collector import create_collector, Article
from privacy_news_monitor.formatter import create_formatter
from privacy_news_monitor.summarizer import summarize_korean_bullets

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


st.set_page_config(page_title="Privacy News Monitor", page_icon="üõ°Ô∏è", layout="wide")

# Custom CSS to make download button more prominent
st.markdown("""
<style>
    /* Make download button bigger and more colorful */
    .stDownloadButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        font-size: 18px !important;
        font-weight: bold !important;
        padding: 16px 32px !important;
        border-radius: 12px !important;
        border: none !important;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4) !important;
        transition: all 0.3s ease !important;
    }
    
    .stDownloadButton > button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6) !important;
    }
    
    .stDownloadButton > button:active {
        transform: translateY(0px) !important;
    }
</style>
""", unsafe_allow_html=True)

st.title("üõ°Ô∏è Ïã§ÏãúÍ∞Ñ Í∞úÏù∏Ï†ïÎ≥¥ Î≥¥Ïïà ÎèôÌñ• Î™®ÎãàÌÑ∞ÎßÅ Î¶¨Ìè¨Ìä∏")
st.caption("Refresh to fetch the latest privacy-related news and categorize it.")

# --- Sidebar: API key status ---
st.sidebar.header("API Keys")
gnews_ok = bool(os.getenv("GNEWS_API_KEY"))
newsapi_ok = bool(os.getenv("NEWSAPI_KEY"))
openai_ok = bool(os.getenv("OPENAI_API_KEY"))
mediastack_ok = bool(os.getenv("MEDIASTACK_API_KEY"))
currents_ok = bool(os.getenv("CURRENTS_API_KEY"))
newsdata_ok = bool(os.getenv("NEWSDATA_API_KEY"))

st.sidebar.write(f"GNEWS_API_KEY: {'‚úÖ' if gnews_ok else '‚ùå'}")
st.sidebar.write(f"NEWSAPI_KEY: {'‚úÖ' if newsapi_ok else '‚ùå'}")
st.sidebar.write(f"OPENAI_API_KEY: {'‚úÖ' if openai_ok else '‚ùå'}")
st.sidebar.write(f"MEDIASTACK_API_KEY: {'‚úÖ' if mediastack_ok else '‚ùå'}")
st.sidebar.write(f"CURRENTS_API_KEY: {'‚úÖ' if currents_ok else '‚ùå'}")
st.sidebar.write(f"NEWSDATA_API_KEY: {'‚úÖ' if newsdata_ok else '‚ùå'}")

st.sidebar.divider()
#use_emoji = st.sidebar.checkbox("Use emoji", value=True)
format_choice = st.sidebar.selectbox("Output format", ["category", "simple", "detailed"], index=0)
do_summaries = st.sidebar.checkbox("Summarize each article (Korean bullets)", value=True)
translate_titles = st.sidebar.checkbox("Translate titles (Korean)", value=True)
use_strict_filter = st.sidebar.checkbox("Use strict privacy filter", value=True, 
                                         help="When enabled, filters out loosely-related articles. Disable to see more results.")

# --- Main controls ---
st.subheader("Latest Privacy Monitor")
st.caption("One click. Latest privacy news. Categorized into Ï†ïÏ±Ö/Í∑úÏ†ú, ÏÇ¨Í±¥/Ï°∞ÏÇ¨, Ïã†Í∏∞Ïà†, Í∏∞ÌÉÄ.")

run = st.button("üîÑ Refresh", type="primary")


MONITOR_QUERY = ( '"data privacy" OR "privacy law" OR "privacy regulation" OR ' '"privacy breach" OR GDPR OR privacy OR ' '"privacy policy" OR "privacy violation" OR "privacy protection" OR ' '"data protection" OR "personal data" OR "consumer privacy" OR ' '"privacy rights" OR "user privacy" OR "information privacy"' )
# Privacy-focused search query - cast a wider net, let relevance filter refine
QUERY_NEWSAPI = MONITOR_QUERY
QUERY_SIMPLE = "data privacy OR privacy law OR GDPR OR privacy breach OR data protection OR consumer privacy"



def markdown_to_pdf(md_text: str) -> bytes:
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=LETTER)
    width, height = LETTER

    # Margins
    x_margin = 1 * inch
    y_margin = 1 * inch
    y = height - y_margin

    # USE KOREAN-SAFE FONT
    c.setFont("HYSMyeongJo-Medium", 10)

    for line in md_text.split("\n"):
        # Wrap long lines safely
        wrapped_lines = wrap(line, 90, replace_whitespace=False)
        if not wrapped_lines:
            y -= 14

        for wl in wrapped_lines:
            if y < y_margin:
                c.showPage()
                c.setFont("HYSMyeongJo-Medium", 10)
                y = height - y_margin

            c.drawString(x_margin, y, wl)
            y -= 14

    c.save()
    buffer.seek(0)
    return buffer.read()


def dedupe_keep_latest(articles: list[Article]) -> list[Article]:
    """Remove duplicate articles based on URL and similar titles"""
    seen_urls = set()
    seen_titles = set()
    out = []
    
    for a in sorted(articles, key=lambda x: x.published_date or "", reverse=True):
        url = (a.url or "").strip().lower()
        # Normalize title for comparison (lowercase, remove extra spaces)
        title = " ".join((a.title or "").lower().split())
        
        # Skip if empty or already seen
        if not url and not title:
            continue
            
        if url and url in seen_urls:
            continue
            
        if title and title in seen_titles:
            continue
        
        # Add to seen sets
        if url:
            seen_urls.add(url)
        if title:
            seen_titles.add(title)
            
        out.append(a)
    
    return out

def is_privacy_relevant(article: Article) -> bool:
    """Check if article is actually about privacy topics - RELAXED filter"""
    # Core privacy keywords - at least one should be present
    privacy_core = [
        "privacy", "gdpr", "personal data",
        "data protection", "privacy policy",
        "privacy law", "privacy regulation", "privacy breach",
        "privacy violation", "privacy rights", "data privacy",
        "personal information", "user data", "surveillance"
    ]
    
    
    text = ((article.title or "") + " " + (article.summary or "")).lower()
    title_lower = (article.title or "").lower()

    
    # Much more relaxed: just needs ONE privacy keyword anywhere
    has_privacy_keyword = any(keyword in text for keyword in privacy_core)
    
    # If we have a privacy keyword, accept it
    if has_privacy_keyword:
        return True
    
    # Even if no direct privacy keyword, check for privacy-adjacent terms
    privacy_adjacent = [
        "data breach", "cyber security", "cybersecurity", "hack",
        "data leak", "information security", "user information",
        "consumer protection", "data law", "data regulation"
    ]
    
    return any(term in text for term in privacy_adjacent)

def pick_20_diverse(articles: list[Article], per_cat: int = 5, total: int = 20) -> list[Article]:
    """Pick diverse articles across categories, avoiding duplicates"""
    ordered = sorted(articles, key=lambda x: x.published_date or "", reverse=True)

    buckets = {"policy": [], "incident": [], "technology": [], "general": []}
    seen_urls = set()
    seen_titles = set()

    for a in ordered:
        # Skip duplicates
        url = (a.url or "").strip().lower()
        title = " ".join((a.title or "").lower().split())
        
        if url and url in seen_urls:
            continue
        if title and title in seen_titles:
            continue
            
        cat = a.category if a.category in buckets else "general"
        if len(buckets[cat]) < per_cat:
            buckets[cat].append(a)
            if url:
                seen_urls.add(url)
            if title:
                seen_titles.add(title)

    out = []
    for cat in ["policy", "incident", "technology", "general"]:
        out.extend(buckets[cat])

    # Fill remaining slots with newest leftovers
    for a in ordered:
        if len(out) >= total:
            break
            
        url = (a.url or "").strip().lower()
        title = " ".join((a.title or "").lower().split())
        
        if url and url in seen_urls:
            continue
        if title and title in seen_titles:
            continue
            
        out.append(a)
        if url:
            seen_urls.add(url)
        if title:
            seen_titles.add(title)

    return out[:total]





@st.cache_data(show_spinner=False)
def translate_title_ko(title: str) -> str:
    if not title:
        return title
    resp = client.responses.create(
        model="gpt-4.1-mini",
        input=f"""Translate this news headline into natural Korean.
Rules:
- Keep proper nouns (company/product/person names) in English if commonly used.
- Keep it short like a real Korean headline.
- Output ONLY the translated headline.

Headline: {title}"""
    )
    return resp.output_text.strip()



# Cache summaries so reruns don't re-bill you
@st.cache_data(show_spinner=False)
def cached_korean_md(title, desc, source):
    bullets = summarize_korean_bullets(title, desc, source)
    return "\n".join([f"- {b}" for b in bullets])

if run:
    collector = create_collector(
        gnews_api_key=os.getenv("GNEWS_API_KEY"),
        newsapi_key=os.getenv("NEWSAPI_KEY"),
    )

    
    with st.spinner("Collecting latest articles..."):
        articles = []
        articles.extend(collector.collect_from_gnews(QUERY_SIMPLE))
        articles.extend(collector.collect_from_newsapi(QUERY_NEWSAPI, max_pages=3))
        articles.extend(collector.collect_from_mediastack(QUERY_SIMPLE, max_pages=4))
        articles.extend(collector.collect_from_currents(QUERY_SIMPLE, max_pages=5))
        articles.extend(collector.collect_from_newsdata(QUERY_SIMPLE, max_pages=10))
        
        # Deduplicate first
        articles = dedupe_keep_latest(articles)
        
        # Filter for privacy relevance (optional)
        if use_strict_filter:
            privacy_articles = [a for a in articles if is_privacy_relevant(a)]
            st.info(f"Found {len(articles)} articles, {len(privacy_articles)} are privacy-relevant (strict filter enabled)")
            articles = privacy_articles
        else:
            st.info(f"Found {len(articles)} articles (strict filter disabled)")
        
        # Pick diverse set from articles
        articles = pick_20_diverse(articles, per_cat=5, total=20)

    if not articles:
        st.warning("No privacy-relevant articles found. This could mean:")
        st.info("‚Ä¢ Not enough recent privacy news in the past 48 hours\n‚Ä¢ API returned mostly non-privacy content\n‚Ä¢ Try disabling 'strict privacy filter' in sidebar\n‚Ä¢ Try checking back later")
        st.stop()

    if len(articles) < 20:
        st.warning(f"Only found {len(articles)} privacy-relevant articles (target: 20). Try disabling strict filter for more results.")
    else:
        st.success(f"‚úÖ Collected {len(articles)} privacy-focused articles (diversified across categories).")

    if translate_titles:
        with st.spinner("Ï†úÎ™© ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠ Ï§ë..."):
            for a in articles:
                try:
                    a.title = translate_title_ko(a.title)
                except Exception:
                    pass

    # Generate Korean summaries (optional)
    if do_summaries:
        with st.spinner("ÌïúÍµ≠Ïñ¥ ÏöîÏïΩ ÏÉùÏÑ± Ï§ë..."):
            for a in articles:
                seed_text = getattr(a, "summary", None) or getattr(a, "description", None)
                try:
                    a.summary = cached_korean_md(a.title, seed_text, a.source)
                except Exception:
                    a.summary = None


    formatter = create_formatter(use_emoji=format_choice)

    if format_choice == "category":
        output_md = formatter.format_by_category(articles)
    elif format_choice == "simple":
        output_md = formatter.format_simple_list(articles)
    else:
        output_md = formatter.format_article_list(articles)

    st.subheader("Report")
    st.markdown(output_md)

    # Eye-catching download button with custom styling
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        pdf_bytes = markdown_to_pdf(output_md)

        pdf_bytes = markdown_to_pdf(output_md)

        st.download_button(
            label="üìÑ Download Report (PDF)",
            data=pdf_bytes,
            file_name="privacy_news_report.pdf",
            mime="application/pdf",
            use_container_width=True,
        )

else:
    st.info("Click üîÑ Refresh to fetch the latest 20 categorized articles.")